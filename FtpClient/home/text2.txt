3D convolutions are commonly employed by demosaicking neural models, in the same way as solving other image restoration problems. 
Counter-intuitively, we show that 3D convolutions implicitly impede the RGB color spectra from exchanging complementary information,
resulting in spectral-inconsistent inference of the local spatial high frequency components. 
As a consequence, shallow 3D convolution networks suffer the Moir¨¦ artifacts, but deep 3D convolutions cause over-smoothness. 
We analyze the fundamental difference between demosaicking and other problems that predict lost pixels between available 
ones (e.g., super-resolution reconstruction),and present the underlying reasons for the confliction between Moir¨¦-free and 
detail-preserving. From the new perspective, our work decouples the common standard convolution procedure to spectral and 
spatial feature aggregations, which allow strengthening global communication in the spectral dimension while respecting 
local contrast in the spatial dimension. We apply our demosaicking model to two tasks: Joint Demosaicking-Denoising and 
Independently Demosaicking. In both applications, our model substantially alleviates artifacts such as Moir¨¦ and over-smoothness
at similar or lower computational cost to currently top-performing models, as validated by diverse evaluations. Source code will 
be released along with paper publication.